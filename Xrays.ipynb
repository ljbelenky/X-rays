{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "import os\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in data 112K rows\n",
    "data = pd.read_csv('Data_Entry_2017.csv')\n",
    "data.drop('Unnamed: 11',axis=1, inplace=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add specific imagepath for correct diagnosis\n",
    "images = {os.path.basename(x): x for x in \n",
    "                   glob(os.path.join('images*', '*', '*.png'))}\n",
    "print('Scans found:', len(images), ', Total Headers', data.shape[0])\n",
    "data['path'] = data['Image Index'].map(images.get)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop ages over 120\n",
    "data = data[data['Patient Age']<120]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diagnosis to predict\n",
    "data['clean_labels'] = data['Finding Labels'].apply(lambda x: x.split('|'))\n",
    "labels = data['clean_labels'].str.join('|').str.get_dummies()\n",
    "data = data.join(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Finding Labels'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['View Position'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Finding Labels'] = data['Finding Labels'].map(lambda x: x.replace('No Finding', ''))\n",
    "from itertools import chain\n",
    "all_labels = np.unique(list(chain(*data['Finding Labels'].map(lambda x: x.split('|')).tolist())))\n",
    "all_labels = [x for x in all_labels if len(x)>0]\n",
    "\n",
    "#all_labels = labels.columns\n",
    "#clean_labels = []\n",
    "#for i in all_labels:\n",
    "#    j = data[i].sum()\n",
    "#    if j >1000:\n",
    "#        clean_labels.append((i,j))\n",
    "#    else:\n",
    "#        print(i)\n",
    "\n",
    "#print(clean_labels)    \n",
    "all_labels = [c_label for c_label in all_labels if data[c_label].sum()>1000]\n",
    "print('Clean Labels ({})'.format(len(all_labels)), \n",
    "      [(c_label,int(data[c_label].sum())) for c_label in all_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop('Hernia', axis=1, inplace=True)\n",
    "labels.drop('Hernia', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since the dataset is very unbiased, we can resample it to be a more reasonable collection\n",
    "# weight is 0.1 + number of findings\n",
    "sample_weights = data['Finding Labels'].map(lambda x: len(x.split('|')) if len(x)>0 else 0).values + 4e-2\n",
    "sample_weights /= sample_weights.sum()\n",
    "data = data.sample(40000, weights=sample_weights)\n",
    "\n",
    "\n",
    "label_counts = data['Finding Labels'].value_counts()[:15]\n",
    "fig, ax1 = plt.subplots(1,1,figsize = (12, 8))\n",
    "ax1.bar(np.arange(len(label_counts))+0.5, label_counts)\n",
    "ax1.set_xticks(np.arange(len(label_counts))+0.5)\n",
    "_ = ax1.set_xticklabels(label_counts.index, rotation = 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['disease_vec'] = data.apply(lambda x: [x[all_labels].values], 1).map(lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_df, test_df = train_test_split(data, \n",
    "                                   test_size = 0.25, \n",
    "                                   random_state = 2018, \n",
    "                                   stratify = data['Finding Labels'].map(lambda x: x[:4]))\n",
    "print('train', train_df.shape[0], 'validation', test_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "image_size = (128, 128)\n",
    "img_gen = ImageDataGenerator(samplewise_center=True, \n",
    "                              samplewise_std_normalization=True, \n",
    "                              horizontal_flip = True, \n",
    "                              vertical_flip = False, \n",
    "                              height_shift_range= 0.05, \n",
    "                              width_shift_range=0.1, \n",
    "                              rotation_range=5, \n",
    "                              shear_range = 0.1,\n",
    "                              fill_mode = 'reflect',\n",
    "                              zoom_range=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['newLabel'] = test_df.apply(lambda x: x['Finding Labels'].split('|'), axis=1)\n",
    "train_df['newLabel'] = train_df.apply(lambda x: x['Finding Labels'].split('|'), axis=1)\n",
    "\n",
    "train_gen = img_gen.flow_from_dataframe(dataframe=train_df, directory=None, x_col = 'path',\n",
    "y_col = 'newLabel', classmode = 'categorical',\n",
    "classes = all_labels, targetsize = image_size, colormode = 'grayscale',\n",
    "batch_size = 32)\n",
    "\n",
    "test_gen = img_gen.flow_from_dataframe(dataframe=test_df, directory=None, x_col = 'path',\n",
    "y_col = 'newLabel', classmode = 'categorical',\n",
    "classes = all_labels, targetsize = image_size, colormode = 'grayscale',\n",
    "batch_size = 256)\n",
    "\n",
    "test_X, test_Y = next(img_gen.flow_from_dataframe(dataframe=test_df,\n",
    "directory=None,\n",
    "x_col = 'path', y_col = 'newLabel',\n",
    "classmode = 'categorical', classes = all_labels,\n",
    "targetsize = image_size,\n",
    "colormode = 'grayscale', batchsize = 2048))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_gen.filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##show top 16 diagnosis\n",
    "diags_list = data['Finding Labels'].value_counts().index[:16]\n",
    "diag_img_list = []\n",
    "for i in diags_list:\n",
    "    k = data[data['Finding Labels'] == i].index[0]\n",
    "    diag_img_list.append(k)\n",
    "\n",
    "imgs = data.filter(diag_img_list, axis=0)\n",
    "imgs['newLabel'] = imgs.apply(lambda x: x['Finding Labels'].split('|'), axis=1)\n",
    "\n",
    "\n",
    "diag_gen = img_gen.flow_from_dataframe(dataframe=imgs, directory=None, x_col = 'path',\n",
    "y_col = 'newLabel', classmode = 'categorical',\n",
    "classes = all_labels, targetsize = image_size, colormode = 'grayscale',\n",
    "batch_size = 32)\n",
    "\n",
    "t_x, t_y = next(diag_gen)\n",
    "fig, m_axs = plt.subplots(4, 4, figsize = (16, 16))\n",
    "for (c_x, c_y, c_ax) in zip(t_x, t_y, m_axs.flatten()):\n",
    "    c_ax.imshow(c_x[:,:,0], cmap = 'bone', vmin = -1.5, vmax = 1.5)\n",
    "    c_ax.set_title(', '.join([n_class for n_class, n_score in zip(all_labels, c_y) \n",
    "                             if n_score>0.5]), fontsize=18)\n",
    "    c_ax.axis('off')\n",
    "    \n",
    "fig.tight_layout()\n",
    "fig.savefig('figures/diagnoses.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.mobilenet import MobileNet\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout, Flatten, MaxPooling2D\n",
    "from tensorflow.keras.models import Sequential\n",
    "base_mobilenet_model = MobileNet(input_shape =  t_x.shape[1:], \n",
    "                                 include_top = False, weights = None)\n",
    "\n",
    "multi_disease_model = Sequential()\n",
    "multi_disease_model.add(base_mobilenet_model)\n",
    "multi_disease_model.add(GlobalAveragePooling2D())\n",
    "multi_disease_model.add(Dropout(0.5))\n",
    "multi_disease_model.add(Dense(512))\n",
    "multi_disease_model.add(Dropout(0.5))\n",
    "multi_disease_model.add(Dense(len(all_labels), activation = 'sigmoid'))\n",
    "multi_disease_model.build(input_shape=image_size)\n",
    "multi_disease_model.compile(optimizer = 'adam', loss = 'binary_crossentropy',\n",
    "                           metrics = ['binary_accuracy', 'mae'])\n",
    "multi_disease_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\n",
    "weight_path=\"{}_weights.best.hdf5\".format('xray_class')\n",
    "\n",
    "checkpoint = ModelCheckpoint(weight_path, monitor='val_loss', verbose=1, \n",
    "                             save_best_only=True, mode='min', save_weights_only = True)\n",
    "\n",
    "early = EarlyStopping(monitor=\"val_loss\", \n",
    "                      mode=\"min\", \n",
    "                      patience=3)\n",
    "callbacks_list = [checkpoint, early]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_disease_model.fit(train_gen, \n",
    "                                  steps_per_epoch=100,\n",
    "                                  validation_data = (test_X, test_Y), \n",
    "                                  epochs = 1, \n",
    "                                  callbacks = callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c_label, s_count in zip(all_labels, 100*np.mean(test_Y,0)):\n",
    "    print('%s: %2.2f%%' % (c_label, s_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_Y = multi_disease_model.predict(test_X, batch_size = 256, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a = np.stack(test_df['disease_vec'].values)\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "fig, c_ax = plt.subplots(1,1, figsize = (9, 9))\n",
    "for (idx, c_label) in enumerate(all_labels):\n",
    "    fpr, tpr, thresholds = roc_curve(test_Y[:,idx].astype(int), pred_Y[:,idx])\n",
    "    c_ax.plot(fpr, tpr, label = '%s (AUC:%0.2f)'  % (c_label, auc(fpr, tpr)))\n",
    "c_ax.legend()\n",
    "c_ax.set_xlabel('False Positive Rate')\n",
    "c_ax.set_ylabel('True Positive Rate')\n",
    "fig.savefig('barely_trained_net.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_disease_model.fit_generator(train_gen, \n",
    "                                  steps_per_epoch = 100,\n",
    "                                  validation_data =  (test_X, test_Y), \n",
    "                                  epochs = 5, \n",
    "                                  callbacks = callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_disease_model.load_weights(weight_path)\n",
    "pred_Y = multi_disease_model.predict(test_X, batch_size = 32, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c_label, p_count, t_count in zip(all_labels, \n",
    "                                     100*np.mean(pred_Y,0), \n",
    "                                     100*np.mean(test_Y,0)):\n",
    "    print('%s: Dx: %2.2f%%, PDx: %2.2f%%' % (c_label, t_count, p_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "fig, c_ax = plt.subplots(1,1, figsize = (9, 9))\n",
    "for (idx, c_label) in enumerate(all_labels):\n",
    "    fpr, tpr, thresholds = roc_curve(test_Y[:,idx].astype(int), pred_Y[:,idx])\n",
    "    c_ax.plot(fpr, tpr, label = '%s (AUC:%0.2f)'  % (c_label, auc(fpr, tpr)))\n",
    "c_ax.legend()\n",
    "c_ax.set_xlabel('False Positive Rate')\n",
    "c_ax.set_ylabel('True Positive Rate')\n",
    "fig.savefig('trained_net.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sickest_idx = np.argsort(np.sum(test_Y, 1)<1)\n",
    "fig, m_axs = plt.subplots(4, 2, figsize = (16, 32))\n",
    "for (idx, c_ax) in zip(sickest_idx, m_axs.flatten()):\n",
    "    c_ax.imshow(test_X[idx, :,:,0], cmap = 'bone')\n",
    "    stat_str = [n_class[:6] for n_class, n_score in zip(all_labels, \n",
    "                                                                  test_Y[idx]) \n",
    "                             if n_score>0.5]\n",
    "    pred_str = ['%s:%2.0f%%' % (n_class[:4], p_score*100)  for n_class, n_score, p_score in zip(all_labels, \n",
    "                                                                  test_Y[idx], pred_Y[idx]) \n",
    "                             if (n_score>0.5) or (p_score>0.5)]\n",
    "    c_ax.set_title('Dx: '+', '.join(stat_str)+'\\nPDx: '+', '.join(pred_str))\n",
    "    c_ax.axis('off')\n",
    "fig.savefig('trained_img_predictions.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_disease_model.fit_generator(train_gen, \n",
    "                                  steps_per_epoch = 100,\n",
    "                                  validation_data =  (test_X, test_Y), \n",
    "                                  epochs = 5, \n",
    "                                  callbacks = callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_Y = multi_disease_model.predict_generator(test_gen, verbose = True)\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valids = [i[-16:] for i in test_gen.filenames]\n",
    "invalids = []\n",
    "for i, j in zip(list(test_df['Image Index']), test_df['Image Index'].index):\n",
    "    if i not in valids:\n",
    "        invalids.append(j)\n",
    "\n",
    "for i in invalids:\n",
    "    test_df.drop(index=i, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['predictions'] = list(pred_Y)\n",
    "test_df['cad'] = test_df['predictions'].apply(lambda x: x.argsort()[-3:][::-1])\n",
    "test_df['cad diagnosis'] = test_df['cad'].apply(lambda x: f'{all_labels[x[0]]} ,{all_labels[x[1]]}  , {all_labels[x[2]]}')\n",
    "test_df['cad likelihoods'] = test_df['predictions'].apply(lambda x: sorted(x, reverse=True)[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['cad diagnosis'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.stack(test_df['disease_vec'].values)\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "fig, c_ax = plt.subplots(1,1, figsize = (9, 9))\n",
    "for (idx, pathology) in enumerate(all_labels):\n",
    "    fpr, tpr, thresholds = roc_curve(a[:,idx].astype(int), pred_Y[:,idx])\n",
    "    c_ax.plot(fpr, tpr, label = '%s (AUC:%0.2f)'  % (pathology, auc(fpr, tpr)))\n",
    "c_ax.legend()\n",
    "c_ax.set_xlabel('False Positive Rate')\n",
    "c_ax.set_ylabel('True Positive Rate')\n",
    "fig.savefig('barely_trained_net.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_disease_model.load_weights(weight_path)\n",
    "pred_Y = multi_disease_model.predict(test_X, batch_size = 32, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c_label, p_count, t_count in zip(all_labels, \n",
    "                                     100*np.mean(pred_Y,0), \n",
    "                                     100*np.mean(test_Y,0)):\n",
    "    print('%s: Dx: %2.2f%%, PDx: %2.2f%%' % (c_label, t_count, p_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "fig, c_ax = plt.subplots(1,1, figsize = (9, 9))\n",
    "for (idx, c_label) in enumerate(all_labels):\n",
    "    fpr, tpr, thresholds = roc_curve(test_Y[:,idx].astype(int), pred_Y[:,idx])\n",
    "    c_ax.plot(fpr, tpr, label = '%s (AUC:%0.2f)'  % (c_label, auc(fpr, tpr)))\n",
    "c_ax.legend()\n",
    "c_ax.set_xlabel('False Positive Rate')\n",
    "c_ax.set_ylabel('True Positive Rate')\n",
    "fig.savefig('trained_net.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(test_X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(test_X[0][:,:,0], cmap='bone')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(test_X[0][:,:,1], cmap='bone')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(test_X[0][:,:,2], cmap='bone')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.applications.ResNet50(\n",
    "    include_top=True, weights='imagenet', input_tensor=None, input_shape=None,\n",
    "    pooling=None, classes=1000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.applications.ResNet50.fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3,3)))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Dense(512))\n",
    "\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "\n",
    "model.add(Conv2D(32, (3,3),activation='sigmoid'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(units=128, activation='relu'))\n",
    "model.add(Dense(units=13, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit_generator(train_gen, \n",
    "                                  steps_per_epoch = 100,\n",
    "                                  validation_data =  (test_X, test_Y), \n",
    "                                  epochs = 1, \n",
    "                                  callbacks = callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_Y = model.predict(test_X, batch_size = 256, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c_label, p_count, t_count in zip(all_labels, \n",
    "                                     100*np.mean(pred_Y,0), \n",
    "                                     100*np.mean(test_Y,0)):\n",
    "    print('%s: Dx: %2.2f%%, PDx: %2.2f%%' % (c_label, t_count, p_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "fig, c_ax = plt.subplots(1,1, figsize = (9, 9))\n",
    "for (idx, c_label) in enumerate(all_labels):\n",
    "    fpr, tpr, thresholds = roc_curve(test_Y[:,idx].astype(int), pred_Y[:,idx])\n",
    "    c_ax.plot(fpr, tpr, label = '%s (AUC:%0.2f)'  % (c_label, auc(fpr, tpr)))\n",
    "c_ax.legend()\n",
    "c_ax.set_xlabel('False Positive Rate')\n",
    "c_ax.set_ylabel('True Positive Rate')\n",
    "fig.savefig('trained_net.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm,\n",
    "                          target_names,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=None,\n",
    "                          normalize=True):\n",
    "    \"\"\"\n",
    "    given a sklearn confusion matrix (cm), make a nice plot\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "    cm:           confusion matrix from sklearn.metrics.confusion_matrix\n",
    "\n",
    "    target_names: given classification classes such as [0, 1, 2]\n",
    "                  the class names, for example: ['high', 'medium', 'low']\n",
    "\n",
    "    title:        the text to display at the top of the matrix\n",
    "\n",
    "    cmap:         the gradient of the values displayed from matplotlib.pyplot.cm\n",
    "                  see http://matplotlib.org/examples/color/colormaps_reference.html\n",
    "                  plt.get_cmap('jet') or plt.cm.Blues\n",
    "\n",
    "    normalize:    If False, plot the raw numbers\n",
    "                  If True, plot the proportions\n",
    "\n",
    "    Usage\n",
    "    -----\n",
    "    plot_confusion_matrix(cm           = cm,                  # confusion matrix created by\n",
    "                                                              # sklearn.metrics.confusion_matrix\n",
    "                          normalize    = True,                # show proportions\n",
    "                          target_names = y_labels_vals,       # list of names of the classes\n",
    "                          title        = best_estimator_name) # title of graph\n",
    "\n",
    "    Citiation\n",
    "    ---------\n",
    "    http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    import itertools\n",
    "\n",
    "    accuracy = np.trace(cm) / float(np.sum(cm))\n",
    "    misclass = 1 - accuracy\n",
    "\n",
    "    if cmap is None:\n",
    "        cmap = plt.get_cmap('Blues')\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "\n",
    "    if target_names is not None:\n",
    "        tick_marks = np.arange(len(target_names))\n",
    "        plt.xticks(tick_marks, target_names, rotation=45)\n",
    "        plt.yticks(tick_marks, target_names)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "\n",
    "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        if normalize:\n",
    "            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "        else:\n",
    "            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n",
    "    plt.savefig('confusion.jpg')\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(cm = confusion_matrix(y_test,y_pred), \n",
    "                      normalize    = False,\n",
    "                      target_names = ['False', 'True'],\n",
    "                      title        = \"Confusion Matrix\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import holoviews as hv\n",
    "from holoviews import opts, dim\n",
    "from bokeh.sampledata.les_mis import data\n",
    "\n",
    "hv.extension('bokeh')\n",
    "hv.output(size=200)\n",
    "\n",
    "links = pd.DataFrame(data['links'])\n",
    "print(links.head(3))\n",
    "\n",
    "hv.Chord(links)\n",
    "\n",
    "nodes = hv.Dataset(pd.DataFrame(data['nodes']), 'index')\n",
    "nodes.data.head()\n",
    "\n",
    "chord = hv.Chord((links, nodes)).select(value=(5, None))\n",
    "chord.opts(\n",
    "    opts.Chord(cmap='Category20', edge_cmap='Category20', edge_color=dim('source').str(), \n",
    "               labels='name', node_color=dim('index').str()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "individual_diagnosis = ['Atelectasis',\n",
    "'Consolidation',\n",
    "'Infiltration',\n",
    "'Pneumothorax',\n",
    "'Edema',\n",
    "'Emphysema',\n",
    "'Fibrosis',\n",
    "'Effusion',\n",
    "'Pneumonia',\n",
    "'Pleural_thickening',\n",
    "'Cardiomegaly',\n",
    "'Nodule Mass',\n",
    "'Hernia']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import holoviews as hv\n",
    "from holoviews import opts, dim\n",
    "from bokeh.sampledata.les_mis import data\n",
    "\n",
    "hv.extension('bokeh')\n",
    "hv.output(size=200)\n",
    "\n",
    "\n",
    "links = pd.DataFrame(data['links'])\n",
    "print(links.head(3))\n",
    "\n",
    "hv.Chord(links)\n",
    "\n",
    "nodes = hv.Dataset(pd.DataFrame(data['nodes']), 'index')\n",
    "nodes.data.head()\n",
    "\n",
    "chord = hv.Chord((links, nodes)).select(value=(5, None))\n",
    "chord.opts(\n",
    "    opts.Chord(cmap='Category20', edge_cmap='Category20', edge_color=dim('source').str(), \n",
    "               labels='name', node_color=dim('index').str()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##128\n",
    "#accuracy: 0.9232 - mae: 0.1234 - val_loss: 0.2367 - val_binary_accuracy: 0.9062 - val_mae: 0.1273\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_Y = multi_disease_model.predict(test_X, batch_size = 1024, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(test_Y[:,idx].astype(int), pred_Y[:,idx])\n",
    "    c_ax.plot(fpr, tpr, label = '%s (AUC:%0.2f)'  % (c_label, auc(fpr, tpr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\n",
    "weight_path=\"{}_model_weights.best.hdf5\".format('xray_class')\n",
    "\n",
    "checkpoint2 = ModelCheckpoint(weight_path, monitor='val_loss', verbose=1, \n",
    "                             save_best_only=True, mode='min', save_weights_only = True)\n",
    "\n",
    "early = EarlyStopping(monitor=\"val_loss\", \n",
    "                      mode=\"min\", \n",
    "                      patience=3)\n",
    "callbacks_list = [checkpoint2, early]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense\n",
    "\n",
    "\n",
    "\n",
    "# dimensions of our images.\n",
    "img_width, img_height = 256, 256\n",
    "\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(256, (2, 2), input_shape=(256,256,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(256, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(256, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(512, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(512, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense((13)))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['binary_accuracy', 'mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_gen, \n",
    "                                  steps_per_epoch=100,\n",
    "                                  validation_data = (test_X, test_Y), \n",
    "                                  epochs = 10, \n",
    "                                  callbacks = callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_Y = model.predict_generator(test_gen, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.stack(test_df['disease_vec'].values)\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = np.array(test_df['disease_vec'].values)\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "fig, c_ax = plt.subplots(1,1, figsize = (9, 9))\n",
    "for (idx, pathology) in enumerate(all_labels):\n",
    "    fpr, tpr, thresholds = roc_curve(a[:,idx].astype(int), pred_Y[:,idx])\n",
    "    c_ax.plot(fpr, tpr, label = '%s (AUC:%0.2f)'  % (pathology, auc(fpr, tpr)))\n",
    "c_ax.legend()\n",
    "c_ax.set_xlabel('False Positive Rate')\n",
    "c_ax.set_ylabel('True Positive Rate')\n",
    "fig.savefig('barely_trained_net.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(test_df['disease_vec'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['disease_vec']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "valids = [i[-16:] for i in test_gen.filenames]\n",
    "invalids = []\n",
    "for i, j in zip(list(test_df['Image Index']), test_df['Image Index'].index):\n",
    "    if i not in valids:\n",
    "        invalids.append(j)\n",
    "\n",
    "for i in invalids:\n",
    "    test_df.drop(index=i, inplace=True)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_df['predictions'] = list(pred_Y)\n",
    "test_df['cad'] = test_df['predictions'].apply(lambda x: x.argsort()[-3:][::-1])\n",
    "test_df['cad diagnosis'] = test_df['cad'].apply(lambda x: f'{all_labels[x[0]]} ,{all_labels[x[1]]}  , {all_labels[x[2]]}')\n",
    "test_df['cad likelihoods'] = test_df['predictions'].apply(lambda x: sorted(x, reverse=True)[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['cad diagnosis'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit_generator(train_gen, \n",
    "                              steps_per_epoch=235,\n",
    "                              validation_data = (test_X, test_Y), \n",
    "                              epochs = 10, \n",
    "                              callbacks = callbacks_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_env",
   "language": "python",
   "name": "test_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
